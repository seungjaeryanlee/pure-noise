# Dataset
dataset: "CelebA-5" # "CIFAR-10-LT" or "CelebA-5" or "CIFAR-10"
train_transform_reprs:
- "RandomHorizontalFlip()"
- "RandomCrop(32, padding=4)"
- "ToTensor()"
- "Normalize((0.5037, 0.4335, 0.3993), (0.3116, 0.2951, 0.2953))"
valid_transform_reprs:
- "ToTensor()"
- "Normalize((0.5037, 0.4335, 0.3993), (0.3116, 0.2951, 0.2953))"

# DataLoader
num_workers: 8
batch_size: 128
enable_oversampling: False
oversampling_start_epoch: 30
oversample_majority_class_num_samples: False
oversample_use_effective_num_sample_weights: False
enable_pin_memory: False

# Model
model: "WideResNet-28-10-torchdistill" # "ResNet-32-m2m" or "ResNet-32-akamaster" or "WideResNet-28-10-torchdistill" or "WideResNet-28-10-xternalz"
dropout_rate: 0.3

# Optimizer
lr: 0.1
momentum: 0.9
weight_decay: 2.0e-4
enable_lr_decay: True
lr_decay: 0.1
lr_decay_epochs: [30, 60]
enable_linear_warmup: True
use_adam: False

# Logging
enable_wandb: True
wandb_name: ""

# Checkpoint
save_ckpt: True
save_ckpt_epochs: [29, 49, 89]
load_ckpt: False
load_ckpt_filepath: "checkpoints/.pt"

# Training
num_epochs: 90

# OPeN
enable_open: False
delta: 0.333333333333333333333333333333333333
pure_noise_mean: [0.5037, 0.4335, 0.3993]
pure_noise_std: [0.3116, 0.2951, 0.2953]
pure_noise_image_size: 32
open_start_epoch: 50

# Debugging
debug_run: False
