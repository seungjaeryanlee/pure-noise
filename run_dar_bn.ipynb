{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['REPO'] = 'pure-noise'\n",
        "os.environ['USER'] = ''\n",
        "os.environ['PASS'] = ''\n",
        "\n",
        "!git clone https://$USER:$PASS@github.com/seungjaeryanlee/$REPO.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyqQMGuCpn2b",
        "outputId": "58d92b5a-1110-4f13-d4ae-826016375d51"
      },
      "id": "pyqQMGuCpn2b",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pure-noise'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 104 (delta 45), reused 79 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (104/104), 3.35 MiB | 3.63 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd pure-noise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV3BL_Qvp3SP",
        "outputId": "17a01af2-8d03-42eb-ef4e-c9ea2b0c941f"
      },
      "id": "OV3BL_Qvp3SP",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pure-noise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrSgUgyLqgcB",
        "outputId": "1ff7e3ca-10fe-4f59-b615-7ae2088db622"
      },
      "id": "XrSgUgyLqgcB",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar10_wideresent_run.ipynb  datasets\t\t\t prepare_data.py\n",
            "code_from_paper.py\t      download_cifar10_lt.ipynb  README.md\n",
            "convert_from_tfrecords.py     images\t\t\t requirements.txt\n",
            "custom_transforms.py\t      imb_datasets\t\t run.ipynb\n",
            "dataset.ipynb\t\t      networks.py\t\t runpod.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbTUcni_qYcO",
        "outputId": "58fc071b-4d4a-4e4f-9618-d856cc87249f"
      },
      "id": "qbTUcni_qYcO",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (1.7.3)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 33.8 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.13.7-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 55.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (0.18.3)\n",
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.0 MB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (2.9.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 21 kB/s \n",
            "\u001b[?25hCollecting tfrecord\n",
            "  Downloading tfrecord-1.14.1.tar.gz (15 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n",
            "Requirement already satisfied: numpy<1.26.0,>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from scipy->-r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 2)) (57.4.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.1-py2.py3-none-any.whl (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 64.7 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 2)) (5.4.8)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 78.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 2)) (2.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 2)) (6.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 2)) (3.19.6)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 2)) (2.23.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 2)) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (3.0.4)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.0-py2.py3-none-any.whl (173 kB)\n",
            "\u001b[K     |████████████████████████████████| 173 kB 83.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 81.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 80.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 78.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 85.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 65.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 84.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 80.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 70.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 81.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 76.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 83.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 80.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 83.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 83.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 3)) (2.8.8)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 3)) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 3)) (2022.10.10)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image->-r requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown->-r requirements.txt (line 4)) (3.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown->-r requirements.txt (line 4)) (4.64.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown->-r requirements.txt (line 4)) (4.6.3)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.51.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.28.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 5)) (14.0.6)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 5)) (4.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 5)) (2.1.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 5)) (0.4.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 73.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 5)) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 5)) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (2.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->-r requirements.txt (line 5)) (3.2.2)\n",
            "Collecting crc32c\n",
            "  Downloading crc32c-2.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 2)) (1.7.1)\n",
            "Building wheels for collected packages: tfrecord, pathtools\n",
            "  Building wheel for tfrecord (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tfrecord: filename=tfrecord-1.14.1-py3-none-any.whl size=15653 sha256=44ff10aae7c8b78ff7500609b5261056a6ed8467e14d3f287f0ba3c68b8c21e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/d3/bb/80b8c03f1ce618f07f1fc58622ca540fdfa413e2c67bba0889\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=7fc2ec7a3ec0b77f92756bbca62dd63157c54388c455652ebca2a3df63413f43\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built tfrecord pathtools\n",
            "Installing collected packages: smmap, gitdb, tensorflow-estimator, tensorboard, shortuuid, setproctitle, sentry-sdk, scipy, pathtools, keras, GitPython, flatbuffers, docker-pycreds, crc32c, wandb, tfrecord, tensorflow, scikit-image, gdown\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed GitPython-3.1.29 crc32c-2.3 docker-pycreds-0.4.0 flatbuffers-22.12.6 gdown-4.6.0 gitdb-4.0.10 keras-2.11.0 pathtools-0.1.2 scikit-image-0.19.3 scipy-1.9.3 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tfrecord-1.14.1 wandb-0.13.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 prepare_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XgfDLZ5qGYP",
        "outputId": "d1c22156-82c5-40ab-a944-6dee889b924f"
      },
      "id": "5XgfDLZ5qGYP",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-26 14:25:07.348951: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-26 14:25:08.348314: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-26 14:25:08.348479: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-26 14:25:08.348501: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NY3lWYRfsTWfsjFPxJUlPumy-WFeD7zK\n",
            "To: /content/pure-noise/tfrecords.zip\n",
            "100% 1.49G/1.49G [00:28<00:00, 52.3MB/s]\n",
            "WARNING:tensorflow:From /content/pure-noise/convert_from_tfrecords.py:58: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /content/pure-noise/convert_from_tfrecords.py:58: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/input.py:262: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/input.py:262: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/input.py:184: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/input.py:184: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/input.py:107: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Dataset.range instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/input.py:107: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Dataset.range instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py:2587: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Dataset.range instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py:2587: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Dataset.range instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/input.py:192: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/input.py:192: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/input.py:191: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/input.py:191: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /content/pure-noise/convert_from_tfrecords.py:60: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
            "WARNING:tensorflow:From /content/pure-noise/convert_from_tfrecords.py:60: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
            "2022-12-26 14:26:00.027475: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /content/pure-noise/convert_from_tfrecords.py:69: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /content/pure-noise/convert_from_tfrecords.py:69: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "done\n",
            "Json has been saved to data/json/cifar10_imbalance50/cifar10_imbalance50_train.json\n",
            "done\n",
            "Json has been saved to data/json/cifar10_imbalance100/cifar10_imbalance100_train.json\n",
            "done\n",
            "Json has been saved to data/json/cifar100_imbalance50/cifar100_imbalance50_train.json\n",
            "done\n",
            "Json has been saved to data/json/cifar100_imbalance100/cifar100_imbalance100_train.json\n",
            "done\n",
            "Json has been saved to data/json/cifar10_imbalance50/cifar10_imbalance50_valid.json\n",
            "done\n",
            "Json has been saved to data/json/cifar10_imbalance100/cifar10_imbalance100_valid.json\n",
            "done\n",
            "Json has been saved to data/json/cifar100_imbalance50/cifar100_imbalance50_valid.json\n",
            "done\n",
            "Json has been saved to data/json/cifar100_imbalance100/cifar100_imbalance100_valid.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout dar-bn\n",
        "!git pull\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYb_s_fHBLG6",
        "outputId": "765a82cf-ea31-4dfa-bd33-bf8a34ee1711"
      },
      "id": "bYb_s_fHBLG6",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'dar-bn' set up to track remote branch 'dar-bn' from 'origin'.\n",
            "Switched to a new branch 'dar-bn'\n",
            "Already up to date.\n",
            "cifar10_wideresent_run.ipynb  download_cifar10_lt.ipynb  README.md\n",
            "code_from_paper.py\t      imb_datasets\t\t requirements.txt\n",
            "convert_from_tfrecords.py     networks_dar_bn.py\t run_dar_bn.ipynb\n",
            "data\t\t\t      networks.py\t\t run.ipynb\n",
            "dataset.ipynb\t\t      prepare_data.py\t\t runpod.sh\n",
            "datasets\t\t      __pycache__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1db3a3c8-f8a6-46f8-9a97-22fd99ba0baa",
      "metadata": {
        "tags": [],
        "id": "1db3a3c8-f8a6-46f8-9a97-22fd99ba0baa"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9734eff9-24c0-46f4-8909-81036431a75b",
      "metadata": {
        "id": "9734eff9-24c0-46f4-8909-81036431a75b"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# transforms.ToTensor() not needed as we use torchvision.io.read_image,\n",
        "# which gives torch.Tensor instead of PIL.Image\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "])\n",
        "valid_transform = transforms.Compose([\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f57e2e98-eec3-4aba-8efb-1fd5d4728552",
      "metadata": {
        "id": "f57e2e98-eec3-4aba-8efb-1fd5d4728552"
      },
      "outputs": [],
      "source": [
        "from datasets.cifar10 import CIFAR10LTDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "56a7bbfa-b4be-4a08-973c-9794c9e20226",
      "metadata": {
        "id": "56a7bbfa-b4be-4a08-973c-9794c9e20226"
      },
      "outputs": [],
      "source": [
        "train_json_filepath = \"data/json/cifar10_imbalance100/cifar10_imbalance100_train.json\"\n",
        "train_images_dirpath = \"data/json/cifar10_imbalance100/images/\"\n",
        "train_dataset = CIFAR10LTDataset(\n",
        "    json_filepath=train_json_filepath,\n",
        "    images_dirpath=train_images_dirpath,\n",
        "    transform=train_transform,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ac486f42-2b29-4d45-a598-385042e0e81c",
      "metadata": {
        "id": "ac486f42-2b29-4d45-a598-385042e0e81c"
      },
      "outputs": [],
      "source": [
        "valid_json_filepath = \"data/json/cifar10_imbalance100/cifar10_imbalance100_valid.json\"\n",
        "valid_images_dirpath = \"data/json/cifar10_imbalance100/images/\"\n",
        "valid_dataset = CIFAR10LTDataset(\n",
        "    json_filepath=valid_json_filepath,\n",
        "    images_dirpath=valid_images_dirpath,\n",
        "    transform=valid_transform,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2bf8745f-6316-4f38-84c1-18581caeb2c8",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bf8745f-6316-4f38-84c1-18581caeb2c8",
        "outputId": "7dbed387-8a50-44ed-8ce2-118c2defb541"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12406, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(train_dataset), len(valid_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d8acab3-8de7-4930-b879-9b2208fa3596",
      "metadata": {
        "id": "4d8acab3-8de7-4930-b879-9b2208fa3596"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "210e0e53-2c2a-40c2-bbd0-886616b0df29",
      "metadata": {
        "id": "210e0e53-2c2a-40c2-bbd0-886616b0df29"
      },
      "outputs": [],
      "source": [
        "# Compute weights\n",
        "import numpy as np\n",
        "\n",
        "labels = np.arange(10)\n",
        "sample_labels = [elem[1] for elem in train_dataset]\n",
        "sample_labels_count = np.array([len(np.where(sample_labels == l)[0]) for l in labels])\n",
        "weights = 1. / sample_labels_count\n",
        "sample_weights = np.array([weights[l] for l in sample_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bccb704e-4d0e-4ac9-94e3-9db48d9a8863",
      "metadata": {
        "id": "bccb704e-4d0e-4ac9-94e3-9db48d9a8863"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "\n",
        "train_sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=50000, # https://stackoverflow.com/a/67802529\n",
        "    replacement=True,\n",
        ")\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    sampler=train_sampler,\n",
        "    batch_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e19d3c2b-d8ef-4fc5-9c08-74d9babe7175",
      "metadata": {
        "id": "e19d3c2b-d8ef-4fc5-9c08-74d9babe7175"
      },
      "outputs": [],
      "source": [
        "valid_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset statistics for pure noise sampling"
      ],
      "metadata": {
        "id": "0vBUtv9jwGCK"
      },
      "id": "0vBUtv9jwGCK"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "QsZM5jvjD2H6"
      },
      "id": "QsZM5jvjD2H6",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples_per_class = torch.from_numpy(sample_labels_count).type(torch.IntTensor).cuda()"
      ],
      "metadata": {
        "id": "4f5ZXHpoxLB5"
      },
      "id": "4f5ZXHpoxLB5",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape = train_dataset[0][0].shape\n",
        "image_size = img_shape[1]"
      ],
      "metadata": {
        "id": "jIRBYJqs2VlV"
      },
      "id": "jIRBYJqs2VlV",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs = torch.stack([img for img, _ in train_dataset]).type(torch.FloatTensor).cuda()"
      ],
      "metadata": {
        "id": "8D9FuBucx68o"
      },
      "id": "8D9FuBucx68o",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_imgs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCb3AEyO2OXG",
        "outputId": "ab5cc542-b9b7-4ba3-a52e-ea18b7acdbe3"
      },
      "id": "LCb3AEyO2OXG",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12406, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_mean = train_imgs.mean(dim=[0,2,3]).cuda()\n",
        "train_dataset_std = train_imgs.std(dim=[0,2,3]).cuda()"
      ],
      "metadata": {
        "id": "U-DZdJSh0zLQ"
      },
      "id": "U-DZdJSh0zLQ",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "869cbd19-4d6b-442c-ad4f-d731160cdc41",
      "metadata": {
        "id": "869cbd19-4d6b-442c-ad4f-d731160cdc41"
      },
      "source": [
        "## Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8025d5c2-6781-42f0-bfb5-5254a9414b2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "8025d5c2-6781-42f0-bfb5-5254a9414b2b",
        "outputId": "eb062333-e328-4d86-9f18-c83b015c4e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "737fbe8e-b9cd-4287-bcbf-2d40b3081acb",
      "metadata": {
        "id": "737fbe8e-b9cd-4287-bcbf-2d40b3081acb"
      },
      "source": [
        "## Prepare Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "208cf7e0-df2f-45a3-849c-49cc542d4a12",
      "metadata": {
        "id": "208cf7e0-df2f-45a3-849c-49cc542d4a12"
      },
      "outputs": [],
      "source": [
        "# Training Hyperparameters\n",
        "N_EPOCH = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling Hyperparameters\n",
        "PURE_NOISE_DELTA = 0.3"
      ],
      "metadata": {
        "id": "S4ii2kh4vz6Z"
      },
      "id": "S4ii2kh4vz6Z",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "451ccd42-20a2-4679-9ef3-9e3f26e72a03",
      "metadata": {
        "id": "451ccd42-20a2-4679-9ef3-9e3f26e72a03"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22c0688-22cf-4900-acc3-c54608332a57",
      "metadata": {
        "id": "f22c0688-22cf-4900-acc3-c54608332a57"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "From xternalz/WideResNet-pytorch\n",
        "\n",
        "https://github.com/xternalz/WideResNet-pytorch/blob/master/wideresnet.py\n",
        "\"\"\"\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.droprate = dropRate\n",
        "        self.equalInOut = (in_planes == out_planes)\n",
        "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
        "                               padding=0, bias=False) or None\n",
        "    def forward(self, x):\n",
        "        if not self.equalInOut:\n",
        "            x = self.relu1(self.bn1(x))\n",
        "        else:\n",
        "            out = self.relu1(self.bn1(x))\n",
        "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
        "        out = self.conv2(out)\n",
        "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
        "\n",
        "class NetworkBlock(nn.Module):\n",
        "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
        "        super(NetworkBlock, self).__init__()\n",
        "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
        "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
        "        layers = []\n",
        "        for i in range(int(nb_layers)):\n",
        "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
        "        super(WideResNet, self).__init__()\n",
        "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
        "        assert((depth - 4) % 6 == 0)\n",
        "        n = (depth - 4) / 6\n",
        "        block = BasicBlock\n",
        "        # 1st conv before any network block\n",
        "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        # 1st block\n",
        "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
        "        # 2nd block\n",
        "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
        "        # 3rd block\n",
        "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
        "        # global average pooling and classifier\n",
        "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
        "        self.nChannels = nChannels[3]\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "    def forward(self, x, noise_mask):\n",
        "        print('input', x.shape)\n",
        "        out = self.conv1(x)\n",
        "        print('conv1', out.shape)\n",
        "        out = self.block1(out)\n",
        "        print('block1', out.shape)\n",
        "        out = self.block2(out)\n",
        "        print('block2', out.shape)\n",
        "        out = self.block3(out)\n",
        "        print('block3', out.shape)\n",
        "        out = self.relu(self.bn1(out))\n",
        "        print('bn-relu', out.shape)\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(-1, self.nChannels)\n",
        "        return self.fc(out)"
      ],
      "metadata": {
        "id": "RjNV0D1_0MFv"
      },
      "id": "RjNV0D1_0MFv",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "From xternalz/WideResNet-pytorch\n",
        "\n",
        "https://github.com/xternalz/WideResNet-pytorch/blob/master/wideresnet.py\n",
        "\n",
        "Replaces BN with DAR-BN (Zada et al.)\n",
        "\"\"\"\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from code_from_paper import dar_bn\n",
        "\n",
        "class BasicBlockDarBn(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
        "        super(BasicBlockDarBn, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.droprate = dropRate\n",
        "        self.equalInOut = (in_planes == out_planes)\n",
        "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
        "                               padding=0, bias=False) or None\n",
        "    def forward(self, x_and_noise_mask):\n",
        "        x, noise_mask = x_and_noise_mask\n",
        "        if not self.equalInOut:\n",
        "            x = self.relu1(dar_bn(self.bn1, x, noise_mask))\n",
        "        else:\n",
        "            out = self.relu1(dar_bn(self.bn1, x, noise_mask))\n",
        "        out = self.relu2(dar_bn(self.bn2, self.conv1(out if self.equalInOut else x), noise_mask))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
        "        out = self.conv2(out)\n",
        "        return [torch.add(x if self.equalInOut else self.convShortcut(x), out), noise_mask]\n",
        "\n",
        "class NetworkBlockDarBn(nn.Module):\n",
        "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
        "        super(NetworkBlockDarBn, self).__init__()\n",
        "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
        "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
        "        layers = []\n",
        "        for i in range(int(nb_layers)):\n",
        "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x_and_noise_mask):\n",
        "        return self.layer(x_and_noise_mask)\n",
        "    \n",
        "class WideResNetDarBn(nn.Module):\n",
        "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
        "        super(WideResNetDarBn, self).__init__()\n",
        "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
        "        assert((depth - 4) % 6 == 0)\n",
        "        n = (depth - 4) / 6\n",
        "        block = BasicBlockDarBn\n",
        "        # 1st conv before any network block\n",
        "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        # 1st block\n",
        "        self.block1 = NetworkBlockDarBn(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
        "        # 2nd block\n",
        "        self.block2 = NetworkBlockDarBn(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
        "        # 3rd block\n",
        "        self.block3 = NetworkBlockDarBn(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
        "        # global average pooling and classifier\n",
        "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
        "        self.nChannels = nChannels[3]\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "    def forward(self, x, noise_mask):\n",
        "        # print(x.shape)\n",
        "        out = self.conv1(x)\n",
        "        # print('conv1', out.shape)\n",
        "        out = self.block1([out, noise_mask])\n",
        "        # print('block1', out[0].shape, out[1].shape)\n",
        "        out = self.block2(out)\n",
        "        # print('block2', out[0].shape, out[1].shape)\n",
        "        out = self.block3(out)\n",
        "        # print('block3', out[0].shape, out[1].shape)\n",
        "        out = self.relu(dar_bn(self.bn1, out[0], noise_mask))\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(-1, self.nChannels)\n",
        "        return self.fc(out)"
      ],
      "metadata": {
        "id": "w2jE4kO2k3tZ"
      },
      "id": "w2jE4kO2k3tZ",
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "09745284-43dc-47f5-9ef9-9bfd479de060",
      "metadata": {
        "id": "09745284-43dc-47f5-9ef9-9bfd479de060"
      },
      "outputs": [],
      "source": [
        "# Model hyperparameters\n",
        "MODEL__WIDERESNET_DEPTH = 28\n",
        "MODEL__WIDERESNET_K = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "7e331334-268a-4fc5-8d6a-21e45b0896f3",
      "metadata": {
        "id": "7e331334-268a-4fc5-8d6a-21e45b0896f3"
      },
      "outputs": [],
      "source": [
        "# from networks import WideResNet\n",
        "\n",
        "net = WideResNetDarBn(\n",
        "    num_classes=10,\n",
        "    depth=MODEL__WIDERESNET_DEPTH,\n",
        "    widen_factor=MODEL__WIDERESNET_K,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "33260cab-02b3-4850-8c4a-e35e80f8e4cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33260cab-02b3-4850-8c4a-e35e80f8e4cd",
        "outputId": "d369a742-7402-4f42-e9db-20c40dadca7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36479194"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "7b4f9a70-ae5a-410d-8640-aa673e981ba7",
      "metadata": {
        "id": "7b4f9a70-ae5a-410d-8640-aa673e981ba7"
      },
      "outputs": [],
      "source": [
        "net = net.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0a69ed-fd35-4c03-9519-0095f4315891",
      "metadata": {
        "id": "bb0a69ed-fd35-4c03-9519-0095f4315891"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "a90c9d5f-e0f1-4765-8c3b-f6d16f23d5e7",
      "metadata": {
        "id": "a90c9d5f-e0f1-4765-8c3b-f6d16f23d5e7"
      },
      "outputs": [],
      "source": [
        "# Optimizer Hyperparameters\n",
        "OPTIM__LR = 0.1\n",
        "OPTIM__MOMENTUM = 0.9\n",
        "OPTIM__WEIGHT_DECAY = 2e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "0e56120d-408a-432d-9eff-ddfd0e37af6c",
      "metadata": {
        "id": "0e56120d-408a-432d-9eff-ddfd0e37af6c"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(\n",
        "    net.parameters(),\n",
        "    lr=OPTIM__LR,\n",
        "    momentum=OPTIM__MOMENTUM,\n",
        "    weight_decay=OPTIM__WEIGHT_DECAY,\n",
        ")\n",
        "scheduler = optim.lr_scheduler.StepLR(\n",
        "    optimizer,\n",
        "    step_size=1,\n",
        "    gamma=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3282946-999f-4ff3-8786-2b17f84eeb31",
      "metadata": {
        "id": "e3282946-999f-4ff3-8786-2b17f84eeb31"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_num = 0"
      ],
      "metadata": {
        "id": "vL4Vh8NcFD4F"
      },
      "id": "vL4Vh8NcFD4F",
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "51ab08a5-1503-4c02-bf5c-4104a8d720dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "44910fe974504df8b379f97b5e7c7001",
            "c7f4e69d41984c5184c79593923e5634",
            "b9a6d5dbcc5f46acb28cd38d92ddc38e",
            "0d2cb807f3a34c119a07b5c624936e8b",
            "decb698c13b1459595f70362ffcacb18",
            "e1ef1bf769c0436f91ec272cc49213d6",
            "76af435f6b624f9a92463dbc750cec7f",
            "0f92fae0ce55476e98f17ffe0a7c9756"
          ]
        },
        "id": "51ab08a5-1503-4c02-bf5c-4104a8d720dc",
        "outputId": "87319506-c899-4d58-97c3-28ec7b3238cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:1h0crm2n) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44910fe974504df8b379f97b5e7c7001"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">olive-universe-55</strong>: <a href=\"https://wandb.ai/brianryan/pure-noise/runs/1h0crm2n\" target=\"_blank\">https://wandb.ai/brianryan/pure-noise/runs/1h0crm2n</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221226_152347-1h0crm2n/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:1h0crm2n). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/pure-noise/wandb/run-20221226_152441-2x5qyjcj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/brianryan/pure-noise/runs/2x5qyjcj\" target=\"_blank\">wobbly-frog-56</a></strong> to <a href=\"https://wandb.ai/brianryan/pure-noise\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb_run = wandb.init(\n",
        "    project=\"pure-noise\",\n",
        "    settings=wandb.Settings(start_method=\"thread\")\n",
        ")\n",
        "\n",
        "wandb.config.update({\n",
        "    # Training\n",
        "    \"n_epoch\": N_EPOCH,\n",
        "    # Optimizer\n",
        "    \"optim__lr\": OPTIM__LR,\n",
        "    \"optim__momentum\": OPTIM__MOMENTUM,\n",
        "    \"optim__weight_decay\": OPTIM__WEIGHT_DECAY,\n",
        "    # Model\n",
        "    \"model__wideresnet_depth\": MODEL__WIDERESNET_DEPTH,\n",
        "    \"model__wideresnet_k\": MODEL__WIDERESNET_K,\n",
        "    # Sampling\n",
        "    \"pure_noise_delta\": PURE_NOISE_DELTA,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def sample_noise_images(image_size, mean, std, count):\n",
        "    \"\"\"Samples pure noise images from the normal distribution N(mean,std)\"\"\"\n",
        "    r = torch.normal(mean[0], std[0], size=(count, 1, image_size, image_size))\n",
        "    g = torch.normal(mean[1], std[1], size=(count, 1, image_size, image_size))\n",
        "    b = torch.normal(mean[2], std[2], size=(count, 1, image_size, image_size))\n",
        "    pure_noise_images = torch.cat((r, g, b), 1)\n",
        "\n",
        "    return pure_noise_images\n",
        "\n",
        "\n",
        "def oversampling_with_pure_noise_train_epoch(\n",
        "    model, balanced_loader, criterion, optimizer, delta, num_samples_per_class,\n",
        "    dataset_mean, dataset_std, image_size,\n",
        "):\n",
        "    \"\"\"Trains model for one epoch according to the OPeN scheme\n",
        "        model : torch.nn.Module;\n",
        "            Model to train\n",
        "        balanced_loader: torch.utils.data.DataLoader\n",
        "            A class balanced loader - samples each class with equal probability\n",
        "        delta: float\n",
        "            Hyper-parameter for OPeN (see description in paper)\n",
        "        num_samples_per_class: torch.IntTensor\n",
        "            Number of samples in each class in the original imbalanced dataset\n",
        "        dataset_mean: torch.FloatTensor of size: (3)\n",
        "            Dataset mean per color channel\n",
        "        dataset_std: torch.FloatTensor of size: (3)\n",
        "            Dataset standard deviation per color channel\n",
        "        image_size: int\n",
        "            Image size - Assumes squared images of size (image_size , image_size)\n",
        "    \"\"\"\n",
        "    train_loss = 0\n",
        "    for images, targets in balanced_loader:\n",
        "        images = images.float().cuda()\n",
        "        targets = targets.cuda()\n",
        "        # Compute representation ratio\n",
        "        max_class_size = torch.max(num_samples_per_class)\n",
        "        representation_ratio = num_samples_per_class[targets] / max_class_size\n",
        "        # Compute probabilities to replace natural images with pure noise images\n",
        "        noise_probs = (1 - representation_ratio) * delta\n",
        "        # Sample indexes to replace with noise according to Bernoulli distribution\n",
        "        noise_indices = torch.nonzero(torch.bernoulli(noise_probs)).view(-1).cuda()\n",
        "        # Replace natural images with sampled pure noise images\n",
        "        noise_images = sample_noise_images(image_size=image_size,\n",
        "        mean=dataset_mean, std=dataset_std, count=len(noise_indices)).cuda()\n",
        "        images[noise_indices] = noise_images\n",
        "        # Create mask for noise images - later used by DAR-BN\n",
        "        noise_mask = torch.zeros(images.size(0), dtype=torch.bool)\n",
        "        noise_mask[noise_indices] = True\n",
        "        # Train model\n",
        "        outputs = model(images, noise_mask)\n",
        "        loss = criterion(outputs, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss * len(targets)\n",
        "    return train_loss"
      ],
      "metadata": {
        "id": "5YSvZEvS_kmw"
      },
      "id": "5YSvZEvS_kmw",
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19ce36b3-5ca3-42d7-b68e-7e0ca4e0c1eb",
      "metadata": {
        "id": "19ce36b3-5ca3-42d7-b68e-7e0ca4e0c1eb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "for epoch_i in range(N_EPOCH):\n",
        "    # Training Phase\n",
        "    net.train()\n",
        "    train_loss = oversampling_with_pure_noise_train_epoch(\n",
        "        model=net,\n",
        "        balanced_loader=train_loader, \n",
        "        criterion=criterion, \n",
        "        optimizer=optimizer, \n",
        "        delta=PURE_NOISE_DELTA, \n",
        "        num_samples_per_class=num_samples_per_class,\n",
        "        dataset_mean=train_dataset_mean,\n",
        "        dataset_std=train_dataset_std,\n",
        "        image_size=image_size)\n",
        "\n",
        "    # Validation Phase\n",
        "    # net.eval()\n",
        "    # with torch.no_grad():\n",
        "    #     valid_loss = 0\n",
        "    #     for minibatch_i, (inputs, labels) in enumerate(valid_loader):\n",
        "    #         inputs = inputs.float().cuda()\n",
        "    #         labels = labels.cuda()\n",
        "\n",
        "    #         outputs = net(inputs)\n",
        "    #         loss = criterion(outputs, labels)\n",
        "    #         valid_loss += loss * len(labels)\n",
        "\n",
        "    wandb.log({\n",
        "        \"train_loss\": train_loss / len(train_dataset),\n",
        "        # \"valid_loss\": valid_loss / len(valid_dataset),\n",
        "    })\n",
        "    if epoch_i in [160, 180]:\n",
        "        scheduler.step()\n",
        "\n",
        "# Finish wandb run\n",
        "wandb_run.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44910fe974504df8b379f97b5e7c7001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7f4e69d41984c5184c79593923e5634",
              "IPY_MODEL_b9a6d5dbcc5f46acb28cd38d92ddc38e"
            ],
            "layout": "IPY_MODEL_0d2cb807f3a34c119a07b5c624936e8b"
          }
        },
        "c7f4e69d41984c5184c79593923e5634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_decb698c13b1459595f70362ffcacb18",
            "placeholder": "​",
            "style": "IPY_MODEL_e1ef1bf769c0436f91ec272cc49213d6",
            "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "b9a6d5dbcc5f46acb28cd38d92ddc38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76af435f6b624f9a92463dbc750cec7f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f92fae0ce55476e98f17ffe0a7c9756",
            "value": 1
          }
        },
        "0d2cb807f3a34c119a07b5c624936e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "decb698c13b1459595f70362ffcacb18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ef1bf769c0436f91ec272cc49213d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76af435f6b624f9a92463dbc750cec7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f92fae0ce55476e98f17ffe0a7c9756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}