{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db3a3c8-f8a6-46f8-9a97-22fd99ba0baa",
   "metadata": {
    "tags": []
   },
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07cb54f7-605e-4b67-a0fb-75dc9d9f6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f57e2e98-eec3-4aba-8efb-1fd5d4728552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.celeba5 import CelebA5Dataset\n",
    "\n",
    "TRAIN_DIR = \"data/CelebA5_64x64/train\"\n",
    "VALID_DIR = \"data/CelebA5_64x64/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8e72ec8-5303-44af-a7cf-fde911d429f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_transforms = [\n",
    "    # transforms.Resize((32,32)),\n",
    "    # transforms.ConvertImageDtype(torch.float32),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e11e29a2-d7e2-435a-9b9b-aeeb805b789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dataset_mean_and_std():\n",
    "    unaugmented_train_dataset = CelebA5Dataset(\n",
    "        dataset_path=TRAIN_DIR,\n",
    "        # transform=transforms.Compose(shared_transforms)\n",
    "    )\n",
    "    \n",
    "    train_imgs = torch.stack([img for img, _ in unaugmented_train_dataset]).type(torch.FloatTensor)\n",
    "    train_dataset_mean = train_imgs.mean(dim=[0,2,3]).cuda()\n",
    "    train_dataset_std = train_imgs.std(dim=[0,2,3]).cuda()\n",
    "    return train_dataset_mean, train_dataset_std\n",
    "    \n",
    "# train_dataset_mean, train_dataset_std = train_dataset_mean_and_std()\n",
    "train_dataset_mean, train_dataset_std = [0.5037, 0.4335, 0.3993], [0.3053, 0.2887, 0.2890]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4090a2eb-4bf5-46d0-91aa-8b7ca93d050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5037, 0.4335, 0.3993] [0.3053, 0.2887, 0.289]\n"
     ]
    }
   ],
   "source": [
    "# tensor([0.5037, 0.4335, 0.3993], device='cuda:0') tensor([0.3053, 0.2887, 0.2890], device='cuda:0')\n",
    "print(train_dataset_mean, train_dataset_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8917ed30-62af-43a3-bf14-87272091f85b",
   "metadata": {},
   "source": [
    "Description from Section D.2:\n",
    "\n",
    "![Description from Section D.2](images/paper__image_augmentations.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9734eff9-24c0-46f4-8909-81036431a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_transforms\n",
    "\n",
    "normalize_transform = transforms.Normalize(train_dataset_mean, train_dataset_std)\n",
    "\n",
    "# transforms.ToTensor() not needed as we use torchvision.io.read_image,\n",
    "# which gives torch.Tensor instead of PIL.Image\n",
    "# Data Augmentation transforms are mostly from Bazinga699/NCL\n",
    "# https://github.com/Bazinga699/NCL/blob/2bbf193/lib/dataset/cui_cifar.py#L64\n",
    "train_transform = transforms.Compose(\n",
    "    shared_transforms + [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(64, padding=4),\n",
    "        custom_transforms.Cutout(n_holes=1, length=16),\n",
    "        # TODO: Check if this is correct values for SIMCLR augmentation\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.RandomApply([\n",
    "            transforms.GaussianBlur(kernel_size=3, sigma=[.1, 2.])\n",
    "        ], p=0.5),\n",
    "    ] + [normalize_transform]\n",
    ")\n",
    "valid_transform = transforms.Compose(\n",
    "    shared_transforms + [normalize_transform]\n",
    ")\n",
    "test_transform = transforms.Compose([\n",
    "    shared_transforms + [normalize_transform]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "56a7bbfa-b4be-4a08-973c-9794c9e20226",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CelebA5Dataset(\n",
    "    dataset_path=TRAIN_DIR,\n",
    "    transform=train_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ac486f42-2b29-4d45-a598-385042e0e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = CelebA5Dataset(\n",
    "    dataset_path=VALID_DIR,\n",
    "    transform=valid_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2bf8745f-6316-4f38-84c1-18581caeb2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6651, 250)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8acab3-8de7-4930-b879-9b2208fa3596",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "139825f5-9b45-4cc7-804e-d864ce2c1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader Hyperparameters\n",
    "DATALOADER__NUM_WORKERS = 8\n",
    "DATALOADER__BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "210e0e53-2c2a-40c2-bbd0-886616b0df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weights\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "sample_labels = []\n",
    "sample_labels_count = np.arange(5)\n",
    "with open(os.path.join(TRAIN_DIR, 'labels.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        _, label = line.split()\n",
    "        label = int(label)\n",
    "        sample_labels.append(label)\n",
    "        sample_labels_count[label] += 1\n",
    "weights = 1. / sample_labels_count\n",
    "sample_weights = np.array([weights[l] for l in sample_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bccb704e-4d0e-4ac9-94e3-9db48d9a8863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=6651, # https://stackoverflow.com/a/67802529\n",
    "    replacement=True,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=DATALOADER__BATCH_SIZE,\n",
    "    num_workers=DATALOADER__NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e19d3c2b-d8ef-4fc5-9c08-74d9babe7175",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=DATALOADER__BATCH_SIZE,\n",
    "    num_workers=DATALOADER__NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c0688-22cf-4900-acc3-c54608332a57",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "09745284-43dc-47f5-9ef9-9bfd479de060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "MODEL__WIDERESNET_DEPTH = 28\n",
    "MODEL__WIDERESNET_K = 10\n",
    "MODEL__WIDERESNET_DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e17c2bf-246f-4846-80f3-8107b001484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks_torchdistill import WideBasicBlock, WideResNet\n",
    "\n",
    "net = WideResNet(\n",
    "    depth=MODEL__WIDERESNET_DEPTH,\n",
    "    k=MODEL__WIDERESNET_K,\n",
    "    dropout_p=MODEL__WIDERESNET_DROPOUT,\n",
    "    block=WideBasicBlock,\n",
    "    num_classes=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7e331334-268a-4fc5-8d6a-21e45b0896f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from networks import WideResNet\n",
    "\n",
    "# # TODO: Consider replacing with https://github.com/yoshitomo-matsubara/torchdistill/blob/main/torchdistill/models/classification/wide_resnet.py\n",
    "# net = WideResNet(\n",
    "#     num_classes=10,\n",
    "#     depth=MODEL__WIDERESNET_DEPTH,\n",
    "#     widen_factor=MODEL__WIDERESNET_K,\n",
    "#     dropRate=MODEL__WIDERESNET_DROPOUT,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33260cab-02b3-4850-8c4a-e35e80f8e4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36475989"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b4f9a70-ae5a-410d-8640-aa673e981ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869cbd19-4d6b-442c-ad4f-d731160cdc41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8025d5c2-6781-42f0-bfb5-5254a9414b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a69ed-fd35-4c03-9519-0095f4315891",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a90c9d5f-e0f1-4765-8c3b-f6d16f23d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer Hyperparameters\n",
    "OPTIM__LR = 0.1\n",
    "OPTIM__MOMENTUM = 0.9\n",
    "OPTIM__WEIGHT_DECAY = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e56120d-408a-432d-9eff-ddfd0e37af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=OPTIM__LR,\n",
    "    momentum=OPTIM__MOMENTUM,\n",
    "    weight_decay=OPTIM__WEIGHT_DECAY,\n",
    ")\n",
    "scheduler = optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=1,\n",
    "    gamma=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737fbe8e-b9cd-4287-bcbf-2d40b3081acb",
   "metadata": {},
   "source": [
    "## Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "208cf7e0-df2f-45a3-849c-49cc542d4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "N_EPOCH = 90\n",
    "SAVE_CKPT_EVERY_N_EPOCH = 10\n",
    "LOAD_CKPT = False\n",
    "LOAD_CKPT_FILEPATH = \"checkpoints/.pt\"\n",
    "LOAD_CKPT_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "451ccd42-20a2-4679-9ef3-9e3f26e72a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3282946-999f-4ff3-8786-2b17f84eeb31",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "046cc698-7fef-486e-b705-da632b963f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(\n",
    "    model,\n",
    "    optimizer,\n",
    "    checkpoint_filepath: str,\n",
    "):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, checkpoint_filepath)\n",
    "\n",
    "\n",
    "def load_checkpoint(\n",
    "    model,\n",
    "    optimizer,\n",
    "    checkpoint_filepath: str,\n",
    "):\n",
    "    checkpoint = torch.load(checkpoint_filepath)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1bf0b5f1-8d8f-45ff-bc2e-7feb04b9aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_CKPT:\n",
    "    load_checkpoint(net, optimizer, LOAD_CKPT_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51ab08a5-1503-4c02-bf5c-4104a8d720dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3qtbeyds) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">worthy-wildflower-95</strong>: <a href=\"https://wandb.ai/brianryan/pure-noise/runs/3qtbeyds\" target=\"_blank\">https://wandb.ai/brianryan/pure-noise/runs/3qtbeyds</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230107_194934-3qtbeyds/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3qtbeyds). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7e720d31ec4d01aaf3136147cab3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0166705136342595, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/pure-noise/wandb/run-20230107_195046-1nt2fx0b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/brianryan/pure-noise/runs/1nt2fx0b\" target=\"_blank\">splendid-glitter-96</a></strong> to <a href=\"https://wandb.ai/brianryan/pure-noise\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_run = wandb.init(\n",
    "    project=\"pure-noise\",\n",
    "    entity=\"brianryan\",\n",
    ")\n",
    "\n",
    "wandb.config.update({\n",
    "    # Data\n",
    "    \"dataloader__num_workers\": DATALOADER__NUM_WORKERS,\n",
    "    \"dataloader__batch_size\": DATALOADER__BATCH_SIZE,\n",
    "    # Optimizer\n",
    "    \"optim__lr\": OPTIM__LR,\n",
    "    \"optim__momentum\": OPTIM__MOMENTUM,\n",
    "    \"optim__weight_decay\": OPTIM__WEIGHT_DECAY,\n",
    "    # Model\n",
    "    \"model__wideresnet_depth\": MODEL__WIDERESNET_DEPTH,\n",
    "    \"model__wideresnet_k\": MODEL__WIDERESNET_K,\n",
    "    \"model__wideresnet_dropout\": MODEL__WIDERESNET_DROPOUT,\n",
    "    # Training\n",
    "    \"n_epoch\": N_EPOCH,\n",
    "    \"save_ckpt_every_n_epoch\": SAVE_CKPT_EVERY_N_EPOCH,\n",
    "    \"load_ckpt\": LOAD_CKPT,\n",
    "    \"load_ckpt_filepath\": LOAD_CKPT_FILEPATH,\n",
    "    \"load_ckpt_epoch\": LOAD_CKPT_EPOCH,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "19ce36b3-5ca3-42d7-b68e-7e0ca4e0c1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "epoch: 20\n",
      "epoch: 21\n",
      "epoch: 22\n",
      "epoch: 23\n",
      "epoch: 24\n",
      "epoch: 25\n",
      "epoch: 26\n",
      "epoch: 27\n",
      "epoch: 28\n",
      "epoch: 29\n",
      "epoch: 30\n",
      "epoch: 31\n",
      "epoch: 32\n",
      "epoch: 33\n",
      "epoch: 34\n",
      "epoch: 35\n",
      "epoch: 36\n",
      "epoch: 37\n",
      "epoch: 38\n",
      "epoch: 39\n",
      "epoch: 40\n",
      "epoch: 41\n",
      "epoch: 42\n",
      "epoch: 43\n",
      "epoch: 44\n",
      "epoch: 45\n",
      "epoch: 46\n",
      "epoch: 47\n",
      "epoch: 48\n",
      "epoch: 49\n",
      "epoch: 50\n",
      "epoch: 53\n",
      "epoch: 54\n",
      "epoch: 55\n",
      "epoch: 56\n",
      "epoch: 57\n",
      "epoch: 58\n",
      "epoch: 59\n",
      "epoch: 60\n",
      "epoch: 61\n",
      "epoch: 62\n",
      "epoch: 63\n",
      "epoch: 64\n",
      "epoch: 65\n",
      "epoch: 66\n",
      "epoch: 67\n",
      "epoch: 68\n",
      "epoch: 69\n",
      "epoch: 70\n",
      "epoch: 71\n",
      "epoch: 72\n",
      "epoch: 73\n",
      "epoch: 74\n",
      "epoch: 75\n",
      "epoch: 76\n",
      "epoch: 77\n",
      "epoch: 78\n",
      "epoch: 79\n",
      "epoch: 80\n",
      "epoch: 81\n",
      "epoch: 82\n",
      "epoch: 83\n",
      "epoch: 84\n",
      "epoch: 85\n",
      "epoch: 86\n",
      "epoch: 87\n",
      "epoch: 88\n",
      "epoch: 89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f89b6ad0d34692975d820f0d8d9319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2366.760 MB of 2366.760 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_i</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▂▃▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████████████████████</td></tr><tr><td>train_acc__class_0</td><td>▂▁▂▃▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇██████████████████</td></tr><tr><td>train_acc__class_1</td><td>▁▃▅▆▇▆▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>train_acc__class_2</td><td>▁▂▃▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>train_acc__class_3</td><td>▁▃▃▃▄▅▅▆▆▆▆▆▆▆▇▇▇█▇█▇▇██████████████████</td></tr><tr><td>train_acc__class_4</td><td>▁▂▂▂▃▃▃▄▄▅▅▅▅▆▆▇▇▇▇▇█▇██████████████████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss__class_0</td><td>██▇▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss__class_1</td><td>█▇▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss__class_2</td><td>█▇▆▆▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss__class_3</td><td>█▆▆▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss__class_4</td><td>█▇▆▆▆▆▅▅▅▄▄▄▄▃▃▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_acc</td><td>▁▂▄▄▃▄▅▇▆▆▇▇▆▆██▇█▇▇█▇▇▇▇▇▇██▇█▇████████</td></tr><tr><td>valid_acc__class_0</td><td>▁▁▁▂▁▄▆█▇▅▆▆▆▄▆▇▆▇▇▆▇▆▆▆▇▆▇▆▇▆▆▆▆▆▆▆▆▆▇▆</td></tr><tr><td>valid_acc__class_1</td><td>▁▂▇▇▆▅▇▇▆█▇▅█▅▇▇▇▇▆▇▇▇▇█▇▇▇█████████████</td></tr><tr><td>valid_acc__class_2</td><td>▅▃▅▃▆▄▁▃▇▆▇█▆█▇█████▇█▇▇██▇▆▆▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>valid_acc__class_3</td><td>▆█▃▁▃▆▆▄▅▁▅▃▂▆▅▅▃▅▃▄▄▄▄▃▄▄▃▄▃▃▄▃▃▄▃▃▃▃▃▃</td></tr><tr><td>valid_acc__class_4</td><td>▁▃▅█▄▁▁▅▁▆▄▇▄▅▇▆▅▆▆▆▅▆▇▆▅▅▅▇▇▇▆▇▇▇▇█████</td></tr><tr><td>valid_loss</td><td>▆▅▆▄█▆▄▁▅▄▃▄▅▂▁▂▃▃▃▃▃▃▃▃▄▄▄▂▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>valid_loss__class_0</td><td>▃▅▆▄█▄▃▁▂▃▂▃▃▃▂▂▂▂▂▂▂▃▃▃▂▃▂▂▂▃▂▃▂▃▃▃▃▃▂▃</td></tr><tr><td>valid_loss__class_1</td><td>█▆▃▃▃▃▂▂▅▁▂▆▁▅▂▃▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>valid_loss__class_2</td><td>█▆▅▇▃▄█▆▂▂▁▁▃▁▂▁▁▂▁▁▂▁▂▂▁▁▂▃▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>valid_loss__class_3</td><td>▃▂▃▃▄▁▂▃▁█▃▆▆▁▂▃▄▄▄▅▄▄▄▄▅▄▅▄▄▄▄▄▄▄▄▅▄▄▄▄</td></tr><tr><td>valid_loss__class_4</td><td>▃▂▃▁▅█▅▁█▂▅▁▅▂▂▃▄▃▃▃▅▄▃▄▅▅▅▃▃▃▄▃▃▃▃▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_i</td><td>89</td></tr><tr><td>train_acc</td><td>0.88498</td></tr><tr><td>train_acc__class_0</td><td>0.95633</td></tr><tr><td>train_acc__class_1</td><td>0.87613</td></tr><tr><td>train_acc__class_2</td><td>0.8695</td></tr><tr><td>train_acc__class_3</td><td>0.76996</td></tr><tr><td>train_acc__class_4</td><td>0.95228</td></tr><tr><td>train_loss</td><td>0.29542</td></tr><tr><td>train_loss__class_0</td><td>0.14597</td></tr><tr><td>train_loss__class_1</td><td>0.32126</td></tr><tr><td>train_loss__class_2</td><td>0.33791</td></tr><tr><td>train_loss__class_3</td><td>0.52082</td></tr><tr><td>train_loss__class_4</td><td>0.15366</td></tr><tr><td>valid_acc</td><td>0.716</td></tr><tr><td>valid_acc__class_0</td><td>0.74</td></tr><tr><td>valid_acc__class_1</td><td>0.94</td></tr><tr><td>valid_acc__class_2</td><td>0.9</td></tr><tr><td>valid_acc__class_3</td><td>0.42</td></tr><tr><td>valid_acc__class_4</td><td>0.58</td></tr><tr><td>valid_loss</td><td>1.0689</td></tr><tr><td>valid_loss__class_0</td><td>1.1468</td></tr><tr><td>valid_loss__class_1</td><td>0.21469</td></tr><tr><td>valid_loss__class_2</td><td>0.35737</td></tr><tr><td>valid_loss__class_3</td><td>1.6835</td></tr><tr><td>valid_loss__class_4</td><td>1.94216</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">splendid-glitter-96</strong>: <a href=\"https://wandb.ai/brianryan/pure-noise/runs/1nt2fx0b\" target=\"_blank\">https://wandb.ai/brianryan/pure-noise/runs/1nt2fx0b</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 9 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230107_195046-1nt2fx0b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "start_epoch_i, end_epoch_i = 0, N_EPOCH\n",
    "if LOAD_CKPT:\n",
    "    start_epoch_i += LOAD_CKPT_EPOCH\n",
    "    end_epoch_i += LOAD_CKPT_EPOCH\n",
    "for epoch_i in range(start_epoch_i, end_epoch_i):\n",
    "    print(f'epoch: {epoch_i}')\n",
    "    # Save checkpoint\n",
    "    if epoch_i % SAVE_CKPT_EVERY_N_EPOCH == 0:\n",
    "        checkpoint_filepath = f\"checkpoints/{wandb.run.name}__epoch_{epoch_i}.pt\"\n",
    "        os.makedirs(\"checkpoints/\", exist_ok=True)\n",
    "        save_checkpoint(net, optimizer, checkpoint_filepath)\n",
    "        wandb.save(checkpoint_filepath)\n",
    "\n",
    "    ## Training Phase\n",
    "    net.train()\n",
    "    train_losses = []\n",
    "    train_labels = []\n",
    "    train_preds = []\n",
    "    for minibatch_i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.float().cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        losses = criterion(outputs, labels)\n",
    "        losses.mean().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        train_losses.extend(losses.cpu().detach().tolist())\n",
    "        train_labels.extend(labels.cpu().detach().tolist())\n",
    "        train_preds.extend(preds.cpu().detach().tolist())\n",
    "\n",
    "    train_losses = np.array(train_losses)\n",
    "    train_labels = np.array(train_labels)\n",
    "    train_preds = np.array(train_preds)\n",
    "\n",
    "    # Filter losses by classes\n",
    "    train_loss_per_class_dict = {\n",
    "        f\"train_loss__class_{class_}\": train_losses[np.where(train_labels == class_)[0]].mean()\n",
    "        for class_ in np.arange(5)\n",
    "    }\n",
    "    # Filter preds by classes for accuracy\n",
    "    train_acc_per_class_dict = {\n",
    "        f\"train_acc__class_{class_}\": (train_preds == train_labels)[np.where(train_labels == class_)[0]].mean()\n",
    "        for class_ in np.arange(5)\n",
    "    }\n",
    "\n",
    "    ## Validation Phase\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        # Save all losses and labels for each example\n",
    "        valid_losses = []\n",
    "        valid_labels = []\n",
    "        valid_preds = []\n",
    "        for minibatch_i, (inputs, labels) in enumerate(valid_loader):\n",
    "            inputs = inputs.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            losses = criterion(outputs, labels)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            valid_losses.extend(losses.cpu().detach().tolist())\n",
    "            valid_labels.extend(labels.cpu().detach().tolist())\n",
    "            valid_preds.extend(preds.cpu().detach().tolist())\n",
    "\n",
    "    valid_losses = np.array(valid_losses)\n",
    "    valid_labels = np.array(valid_labels)\n",
    "    valid_preds = np.array(valid_preds)\n",
    "\n",
    "    # Filter losses by classes\n",
    "    valid_loss_per_class_dict = {\n",
    "        f\"valid_loss__class_{class_}\": valid_losses[np.where(valid_labels == class_)[0]].mean()\n",
    "        for class_ in np.arange(5)\n",
    "    }\n",
    "    # Filter preds by classes for accuracy\n",
    "    valid_acc_per_class_dict = {\n",
    "        f\"valid_acc__class_{class_}\": (valid_preds == valid_labels)[np.where(valid_labels == class_)[0]].mean()\n",
    "        for class_ in np.arange(5)\n",
    "    }\n",
    "\n",
    "    # Logging\n",
    "    wandb.log({\n",
    "        \"epoch_i\": epoch_i,\n",
    "        \"train_loss\": np.mean(train_losses),\n",
    "        \"train_acc\": np.mean(train_preds == train_labels),\n",
    "        **train_loss_per_class_dict,\n",
    "        **train_acc_per_class_dict,\n",
    "        \"valid_loss\": np.mean(valid_losses),\n",
    "        \"valid_acc\": np.mean(valid_preds == valid_labels),\n",
    "        **valid_loss_per_class_dict,\n",
    "        **valid_acc_per_class_dict,\n",
    "    })\n",
    "    if epoch_i in [30, 60]:\n",
    "        scheduler.step()\n",
    "\n",
    "# Finish wandb run\n",
    "wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d388e7d-350e-4c8d-a97c-834baa2469a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
