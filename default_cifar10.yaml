# Dataset
dataset: "CIFAR-10" #  "CIFAR-10-LT" or "CelebA-5" or "CIFAR-10"
train_transform_reprs:
- "RandomHorizontalFlip()"
- "RandomCrop(32, padding=4)"
- "ToTensor()"
- "Normalize((0.491400808095932, 0.48215898871421814, 0.44653093814849854), (0.24703224003314972, 0.24348513782024384, 0.26158785820007324))"
valid_transform_reprs:
- "ToTensor()"
- "Normalize((0.491400808095932, 0.48215898871421814, 0.44653093814849854), (0.24703224003314972, 0.24348513782024384, 0.26158785820007324))"

# DataLoader
num_workers: 8
batch_size: 128
enable_oversampling: False
oversampling_start_epoch: 160
oversample_majority_class_num_samples: False
oversample_use_effective_num_sample_weights: True
enable_pin_memory: False

# Model
model: "WideResNet-28-10-torchdistill" # "ResNet-32-m2m" or "ResNet-32-akamaster" or "WideResNet-28-10-torchdistill" or "WideResNet-28-10-xternalz"
dropout_rate: 0.3

# Optimizer
lr: 0.1
momentum: 0.9
weight_decay: 2.0e-4
lr_decay: 0.01
lr_decay_epochs: [160, 180]
enable_linear_warmup: False

# Logging
enable_wandb: True
wandb_name: ""

# Checkpoint
save_ckpt: True
save_ckpt_epochs: [159, 199]
load_ckpt: False
load_ckpt_filepath: "checkpoints/.pt"

# Training
num_epochs: 200

# OPeN
enable_open: False
delta: 0.333333333333333333333333333333333333
pure_noise_mean: [0.491400808095932, 0.48215898871421814, 0.44653093814849854]
pure_noise_std: [0.24703224003314972, 0.24348513782024384, 0.26158785820007324]
pure_noise_image_size: 32
open_start_epoch: 160

# Debugging
debug_run: False