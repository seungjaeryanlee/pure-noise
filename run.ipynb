{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db3a3c8-f8a6-46f8-9a97-22fd99ba0baa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8917ed30-62af-43a3-bf14-87272091f85b",
   "metadata": {},
   "source": [
    "Description from Section D.2:\n",
    "\n",
    "![Description from Section D.2](images/paper__image_augmentations.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9734eff9-24c0-46f4-8909-81036431a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import custom_transforms\n",
    "\n",
    "# transforms.ToTensor() not needed as we use torchvision.io.read_image,\n",
    "# which gives torch.Tensor instead of PIL.Image\n",
    "# Data Augmentation transforms are mostly from Bazinga699/NCL\n",
    "# https://github.com/Bazinga699/NCL/blob/2bbf193/lib/dataset/cui_cifar.py#L64\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    custom_transforms.Cutout(n_holes=1, length=16),\n",
    "    # TODO: Check if this is correct values for SIMCLR augmentation\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "    ], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomApply([\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=[.1, 2.])\n",
    "    ], p=0.5),\n",
    "    # TODO: Verify where this number comes from: is it CIFAR-10 or CIFAR-10-LT?\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ConvertImageDtype(torch.float32),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57e2e98-eec3-4aba-8efb-1fd5d4728552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.cifar10 import CIFAR10LTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a7bbfa-b4be-4a08-973c-9794c9e20226",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json_filepath = \"data/json/cifar10_imbalance100/cifar10_imbalance100_train.json\"\n",
    "train_images_dirpath = \"data/json/cifar10_imbalance100/images/\"\n",
    "train_dataset = CIFAR10LTDataset(\n",
    "    json_filepath=train_json_filepath,\n",
    "    images_dirpath=train_images_dirpath,\n",
    "    transform=train_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac486f42-2b29-4d45-a598-385042e0e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_json_filepath = \"data/json/cifar10_imbalance100/cifar10_imbalance100_valid.json\"\n",
    "valid_images_dirpath = \"data/json/cifar10_imbalance100/images/\"\n",
    "valid_dataset = CIFAR10LTDataset(\n",
    "    json_filepath=valid_json_filepath,\n",
    "    images_dirpath=valid_images_dirpath,\n",
    "    transform=valid_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf8745f-6316-4f38-84c1-18581caeb2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12406, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8acab3-8de7-4930-b879-9b2208fa3596",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "139825f5-9b45-4cc7-804e-d864ce2c1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader Hyperparameters\n",
    "DATALOADER__NUM_WORKERS = 4\n",
    "DATALOADER__BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "210e0e53-2c2a-40c2-bbd0-886616b0df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weights\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "labels = np.arange(10)\n",
    "with open(train_json_filepath, \"r\") as f:\n",
    "    json_data = json.load(f)\n",
    "sample_labels = [annotation[\"category_id\"] for annotation in json_data[\"annotations\"]]\n",
    "sample_labels_count = np.array([len(np.where(sample_labels == l)[0]) for l in labels])\n",
    "weights = 1. / sample_labels_count\n",
    "sample_weights = np.array([weights[l] for l in sample_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bccb704e-4d0e-4ac9-94e3-9db48d9a8863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "train_sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=50000, # https://stackoverflow.com/a/67802529\n",
    "    replacement=True,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    batch_size=DATALOADER__BATCH_SIZE,\n",
    "    num_workers=DATALOADER__NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e19d3c2b-d8ef-4fc5-9c08-74d9babe7175",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=DATALOADER__BATCH_SIZE,\n",
    "    num_workers=DATALOADER__NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c0688-22cf-4900-acc3-c54608332a57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09745284-43dc-47f5-9ef9-9bfd479de060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "MODEL__WIDERESNET_DEPTH = 28\n",
    "MODEL__WIDERESNET_K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e331334-268a-4fc5-8d6a-21e45b0896f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import WideResNet\n",
    "\n",
    "net = WideResNet(\n",
    "    num_classes=10,\n",
    "    depth=MODEL__WIDERESNET_DEPTH,\n",
    "    widen_factor=MODEL__WIDERESNET_K,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33260cab-02b3-4850-8c4a-e35e80f8e4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36479194"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b4f9a70-ae5a-410d-8640-aa673e981ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869cbd19-4d6b-442c-ad4f-d731160cdc41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8025d5c2-6781-42f0-bfb5-5254a9414b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseungjaeryanlee\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a69ed-fd35-4c03-9519-0095f4315891",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90c9d5f-e0f1-4765-8c3b-f6d16f23d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer Hyperparameters\n",
    "OPTIM__LR = 0.1\n",
    "OPTIM__MOMENTUM = 0.9\n",
    "OPTIM__WEIGHT_DECAY = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e56120d-408a-432d-9eff-ddfd0e37af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=OPTIM__LR,\n",
    "    momentum=OPTIM__MOMENTUM,\n",
    "    weight_decay=OPTIM__WEIGHT_DECAY,\n",
    ")\n",
    "scheduler = optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=1,\n",
    "    gamma=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737fbe8e-b9cd-4287-bcbf-2d40b3081acb",
   "metadata": {},
   "source": [
    "## Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "208cf7e0-df2f-45a3-849c-49cc542d4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "N_EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "451ccd42-20a2-4679-9ef3-9e3f26e72a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3282946-999f-4ff3-8786-2b17f84eeb31",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51ab08a5-1503-4c02-bf5c-4104a8d720dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseungjaeryanlee\u001b[0m (\u001b[33mbrianryan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/pure-noise/wandb/run-20221225_154718-tmjufxmb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/brianryan/pure-noise/runs/tmjufxmb\" target=\"_blank\">magic-plasma-24</a></strong> to <a href=\"https://wandb.ai/brianryan/pure-noise\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_run = wandb.init(\n",
    "    project=\"pure-noise\",\n",
    "    entity=\"brianryan\",\n",
    ")\n",
    "\n",
    "wandb.config.update({\n",
    "    # Data\n",
    "    \"dataloader__num_workers\": DATALOADER__NUM_WORKERS,\n",
    "    \"dataloader__batch_size\": DATALOADER__BATCH_SIZE,\n",
    "    # Optimizer\n",
    "    \"optim__lr\": OPTIM__LR,\n",
    "    \"optim__momentum\": OPTIM__MOMENTUM,\n",
    "    \"optim__weight_decay\": OPTIM__WEIGHT_DECAY,\n",
    "    # Model\n",
    "    \"model__wideresnet_depth\": MODEL__WIDERESNET_DEPTH,\n",
    "    \"model__wideresnet_k\": MODEL__WIDERESNET_K,\n",
    "    # Training\n",
    "    \"n_epoch\": N_EPOCH,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ce36b3-5ca3-42d7-b68e-7e0ca4e0c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "for epoch_i in range(N_EPOCH):\n",
    "    # Training Phase\n",
    "    net.train()\n",
    "    train_losses = []\n",
    "    train_labels = []\n",
    "    for minibatch_i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.float().cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        losses = criterion(outputs, labels)\n",
    "        losses.mean().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.extend(losses.cpu().detach().tolist())\n",
    "        train_labels.extend(labels.cpu().detach().tolist())\n",
    "\n",
    "    train_losses = np.array(train_losses)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # Filter losses by classes\n",
    "    train_loss_per_class_dict = {\n",
    "        f\"train_loss__class_{class_}\": train_losses[np.where(train_labels == class_)[0]].mean()\n",
    "        for class_ in np.arange(10)\n",
    "    }\n",
    "\n",
    "    # Validation Phase\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        # Save all losses and labels for each example\n",
    "        valid_losses = []\n",
    "        valid_labels = []\n",
    "        for minibatch_i, (inputs, labels) in enumerate(valid_loader):\n",
    "            inputs = inputs.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            losses = criterion(outputs, labels)\n",
    "\n",
    "            valid_losses.extend(losses.cpu().detach().tolist())\n",
    "            valid_labels.extend(labels.cpu().detach().tolist())\n",
    "\n",
    "        valid_losses = np.array(valid_losses)\n",
    "        valid_labels = np.array(valid_labels)\n",
    "\n",
    "        # Filter losses by classes\n",
    "        valid_loss_per_class_dict = {\n",
    "            f\"valid_loss__class_{class_}\": valid_losses[np.where(valid_labels == class_)[0]].mean()\n",
    "            for class_ in np.arange(10)\n",
    "        }\n",
    "\n",
    "    wandb.log({\n",
    "        \"train_loss\": np.mean(train_losses),\n",
    "        **train_loss_per_class_dict,\n",
    "        \"valid_loss\": np.mean(valid_losses),\n",
    "        **valid_loss_per_class_dict,\n",
    "    })\n",
    "    if epoch_i in [160, 180]:\n",
    "        scheduler.step()\n",
    "\n",
    "# Finish wandb run\n",
    "wandb_run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
