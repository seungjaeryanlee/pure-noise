{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d5556c-88ee-45e7-9f1e-12c5e818c96a",
   "metadata": {},
   "source": [
    "## Download and unzip ZIP File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56280143-7525-4cd1-9bcf-4ffa146c3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c3d1015-ffa3-476f-a52d-c652abfa6b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1NY3lWYRfsTWfsjFPxJUlPumy-WFeD7zK\n",
      "To: /root/pure-noise/data.zip\n",
      "100%|██████████████████████████████████████████████████████████| 1.49G/1.49G [00:06<00:00, 217MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data.zip'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=1NY3lWYRfsTWfsjFPxJUlPumy-WFeD7zK'\n",
    "output = 'data.zip'\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef65f311-d3b0-4847-a439-41ddeb6afafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"data.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf9437b-58df-421f-9e79-70b0dd80504a",
   "metadata": {},
   "source": [
    "## Load TFRecords to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb66694b-4f2a-429b-b484-e6a1367d4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow tfrecord -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b45db7a-cf3e-45f5-8558-aebab5081fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tfrecord.torch.dataset import TFRecordDataset\n",
    "\n",
    "tfrecord_path = \"data/cifar-10-data-im-0.01/train.tfrecords\"\n",
    "index_path = None\n",
    "description = { \"image\": \"byte\", \"label\": \"int\" }\n",
    "dataset = TFRecordDataset(tfrecord_path, index_path, description)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e40b4abd-1e49-4639-8bb9-c833b5e12c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3072])\n",
      "torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(loader))\n",
    "print(data[\"image\"].shape)\n",
    "print(data[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ae36d-9edd-4827-9def-96d02b49e358",
   "metadata": {},
   "source": [
    "## Convert TFRecords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9de9c46d-a3cf-4fea-9f87-4994534fb6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2b7d26a-0e4a-412c-861b-fccd52b2d196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import cv2, os, json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            \"image\": tf.FixedLenFeature([], tf.string),\n",
    "            \"label\": tf.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.decode_raw(features[\"image\"], tf.uint8)\n",
    "    image.set_shape([3*32*32])\n",
    "    label = tf.cast(features[\"label\"], tf.int32)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def convert_from_tfrecords(data_root, dir_name, num_class, mode, output_path, json_file_prefix):\n",
    "    if mode == 'valid':\n",
    "        tfrecord_path = os.path.join(data_root, dir_name, 'eval.tfrecords')\n",
    "    else:\n",
    "        tfrecord_path = os.path.join(data_root, dir_name, 'train.tfrecords')\n",
    "    filename_queue = tf.train.string_input_producer([tfrecord_path], shuffle=False, num_epochs=1)\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    image, label = read_and_decode(filename_queue)\n",
    "\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess = tf.Session()\n",
    "    sess.run(init_op)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    annotations = []\n",
    "    try:\n",
    "        step = 0\n",
    "        while not coord.should_stop():\n",
    "            images, labels = sess.run([image, label])\n",
    "            images = cv2.cvtColor(images.reshape(3, 32, 32).transpose(1, 2, 0), cv2.COLOR_RGB2BGR)\n",
    "            im_path = os.path.join(output_path, json_file_prefix, 'images', str(labels))\n",
    "            if not os.path.exists(im_path):\n",
    "                os.makedirs(im_path)\n",
    "            save_path = os.path.join(im_path, '{}_{}.jpg'.format(mode, step))\n",
    "            cv2.imwrite(save_path, images)\n",
    "            annotations.append({'fpath': save_path, 'image_id': step, 'category_id':int(labels)})\n",
    "            step += 1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('done')\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "\n",
    "    with open(os.path.join(output_path, json_file_prefix, json_file_prefix+'_{}.json'.format(mode)), 'w') as f:\n",
    "        json.dump({'annotations': annotations, 'num_classes': num_class}, f)\n",
    "\n",
    "    print('Json has been saved to', os.path.join(output_path, json_file_prefix, json_file_prefix+'_{}.json'.format(mode)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe3c1298-7985-432a-b87e-791c0eb202a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_9046/710553408.py:28: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/input.py:272: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/input.py:184: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/input.py:107: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py:2587: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/input.py:193: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/input.py:193: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_9046/710553408.py:30: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_9046/710553408.py:39: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 10:03:24.524589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2022-12-22 10:03:24.524668: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-22 10:03:24.524905: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 10:03:24.532444: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Json has been saved to converted_data/cifar10_imbalance50/cifar10_imbalance50_train.json\n",
      "done\n",
      "Json has been saved to converted_data/cifar10_imbalance100/cifar10_imbalance100_train.json\n",
      "done\n",
      "Json has been saved to converted_data/cifar100_imbalance100/cifar100_imbalance100_train.json\n",
      "done\n",
      "Json has been saved to converted_data/cifar100_imbalance50/cifar100_imbalance50_train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 10:03:46.158595: W tensorflow/c/c_api.cc:291] Operation '{name:'input_producer/limit_epochs/epochs/Assign' id:12 op device:{requested: '', assigned: ''} def:{{{node input_producer/limit_epochs/epochs/Assign}} = Assign[T=DT_INT64, _class=[\"loc:@input_producer/limit_epochs/epochs\"], _has_manual_control_dependencies=true, use_locking=true, validate_shape=true](input_producer/limit_epochs/epochs, input_producer/limit_epochs/Const)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Json has been saved to converted_data/cifar10_imbalance50/cifar10_imbalance50_valid.json\n",
      "done\n",
      "Json has been saved to converted_data/cifar10_imbalance100/cifar10_imbalance100_valid.json\n",
      "done\n",
      "Json has been saved to converted_data/cifar100_imbalance100/cifar100_imbalance100_valid.json\n",
      "done\n",
      "Json has been saved to converted_data/cifar100_imbalance50/cifar100_imbalance50_valid.json\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "modes = ['train', 'valid']\n",
    "args = SimpleNamespace(input_path=\"data/\", output_path=\"converted_data/\")\n",
    "\n",
    "cifar10_im50 = {'dir': 'cifar-10-data-im-0.02', 'json': 'cifar10_imbalance50', 'class': 10}\n",
    "cifar10_im100 = {'dir': 'cifar-10-data-im-0.01', 'json': 'cifar10_imbalance100', 'class':10}\n",
    "cifar100_im50 = {'dir': 'cifar-100-data-im-0.02', 'json': 'cifar100_imbalance50', 'class':100}\n",
    "cifar100_im100 = {'dir': 'cifar-100-data-im-0.01', 'json': 'cifar100_imbalance100', 'class': 100}\n",
    "\n",
    "for m in modes:\n",
    "    convert_from_tfrecords(\n",
    "        args.input_path, cifar10_im50['dir'],\n",
    "        cifar10_im50['class'], m, args.output_path,\n",
    "        cifar10_im50['json']\n",
    "    )\n",
    "    convert_from_tfrecords(\n",
    "        args.input_path, cifar10_im100['dir'],\n",
    "        cifar10_im100['class'], m, args.output_path,\n",
    "        cifar10_im100['json']\n",
    "    )\n",
    "    convert_from_tfrecords(\n",
    "        args.input_path, cifar100_im100['dir'],\n",
    "        cifar100_im100['class'], m, args.output_path,\n",
    "        cifar100_im100['json']\n",
    "    )\n",
    "    convert_from_tfrecords(\n",
    "        args.input_path, cifar100_im50['dir'],\n",
    "        cifar100_im50['class'], m, args.output_path,\n",
    "        cifar100_im50['json']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78dc20d-d257-4c65-8c22-da44fcb60f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
